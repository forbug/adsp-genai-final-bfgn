{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granularily Test the Graph Implementation\n",
    "Use this notebook to stress test the graph implementation. Identify where there are bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Text-only collection loaded - will use optimized text search when no image is provided\n"
     ]
    }
   ],
   "source": [
    "from conv_ai_ecommerce.data_ingestion.chroma_loader import load_chroma_index, load_dual_collections\n",
    "from conv_ai_ecommerce.vlrag_framework.graph import create_enhanced_workflow\n",
    "from conv_ai_ecommerce.vlrag_framework.prompts import create_response_chain\n",
    "import clip\n",
    "\n",
    "def load_data():\n",
    "    # Try to load both collections\n",
    "    try:\n",
    "        collections = load_dual_collections(\"../data/chroma_index\")\n",
    "        multimodal_collection = collections['multimodal']['collection']\n",
    "        multimodal_metadata = collections['multimodal']['metadata']\n",
    "        text_only_collection = collections['text_only']['collection']\n",
    "        text_only_metadata = collections['text_only']['metadata']\n",
    "        \n",
    "        if text_only_collection is not None:\n",
    "            print(\"ðŸ’¡ Text-only collection loaded - will use optimized text search when no image is provided\")\n",
    "    except Exception as e:\n",
    "        # Fallback to regular loading\n",
    "        print(f\"Could not load dual collections, using multimodal only: {e}\")\n",
    "        multimodal_collection, multimodal_metadata = load_chroma_index(\"../data/chroma_index\")\n",
    "        text_only_collection, text_only_metadata = None, None\n",
    "    \n",
    "    clip_model, _ = clip.load(\"ViT-B/32\", device=\"cpu\")\n",
    "    workflow = create_enhanced_workflow()\n",
    "    response_chain = create_response_chain()\n",
    "    \n",
    "    return (multimodal_collection, multimodal_metadata, \n",
    "            text_only_collection, text_only_metadata, \n",
    "            clip_model, workflow, response_chain)\n",
    "\n",
    "(collection, meta_df, text_only_collection, text_only_metadata, \n",
    " clip_model, workflow, response_chain) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "user_input = \"What funko pops are you aware of?\"\n",
    "image_file = None\n",
    "\n",
    "# Embed user query\n",
    "text_input = clip.tokenize([user_input], truncate=True)\n",
    "with torch.no_grad():\n",
    "    query_emb = clip_model.encode_text(text_input).cpu().numpy()\n",
    "\n",
    "image_emb = np.zeros_like(query_emb)\n",
    "\n",
    "state = {\n",
    "    \"user_input\": user_input,\n",
    "    \"user_embedding\": query_emb,\n",
    "    \"image_embedding\": image_emb,\n",
    "    \"has_image\": image_file is not None,  # Track if image was provided\n",
    "    \"vector_index\": collection,\n",
    "    \"metadata_df\": meta_df,\n",
    "    \"text_only_collection\": text_only_collection,  # Add text-only collection\n",
    "    \"text_only_metadata\": text_only_metadata,      # Add text-only metadata\n",
    "    \"response_chain\": response_chain,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "user_embedding = query_emb\n",
    "if image_file is not None:\n",
    "    collection = state['vector_index']\n",
    "    metadata_df = state['metadata_df']\n",
    "    # Squeeze to 1D and then combine\n",
    "    text_emb_1d = user_embedding.squeeze()\n",
    "    image_emb_1d = image_embedding.squeeze()\n",
    "    search_emb = np.concatenate([text_emb_1d, image_emb_1d]).astype(\"float32\")\n",
    "elif state.get('text_only_collection') is not None:\n",
    "    collection = state['text_only_collection']\n",
    "    metadata_df = state['text_only_metadata']\n",
    "    search_emb = user_embedding.squeeze().astype(\"float32\")\n",
    "else:\n",
    "    # Fallback to multimodal if text-only is not available, but use only text embedding\n",
    "    collection = state['vector_index']\n",
    "    metadata_df = state['metadata_df']\n",
    "    # Here, we need to construct a query that matches the multimodal embedding structure,\n",
    "    # but with a zero-vector for the image part.\n",
    "    text_emb_1d = text_embedding.squeeze()\n",
    "    image_emb_placeholder = np.zeros_like(text_emb_1d) # Assuming image embedding dim is same as text\n",
    "    search_emb = np.concatenate([text_emb_1d, image_emb_placeholder]).astype(\"float32\")\n",
    "\n",
    "# Retrieve relevant documents\n",
    "results = collection.query(\n",
    "    query_embeddings=[search_emb.tolist()],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# Get indices from the results\n",
    "if results['ids'] and len(results['ids'][0]) > 0:\n",
    "    indices = [int(doc_id) for doc_id in results['ids'][0]]\n",
    "    source_data = metadata_df.iloc[indices]\n",
    "else:\n",
    "    # Fallback to empty dataframe if no results\n",
    "    source_data = metadata_df.iloc[:0].copy()\n",
    "\n",
    "state['source_data'] = source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['2645', '7741', '8822']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[None, None, None]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'description': '- -: - -\" | - -: - -. -. - - | - - -, - - - - - - - - | - - - - -.',\n",
       "    'image_url': 'https://images-na.ssl-images-amazon.com/images/I/31An4Vzy6eL.jpg|https://images-na.ssl-images-amazon.com/images/I/315AP21SrbL.jpg|https://images-na.ssl-images-amazon.com/images/I/41zUf%2B2OHtL.jpg|https://images-na.ssl-images-amazon.com/images/I/410Pbq%2BxgsL.jpg|https://images-na.ssl-images-amazon.com/images/I/41locO2ICcL.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg',\n",
       "    'name': '-',\n",
       "    'uniq_id': '4b6ee3211515a424ab63b0adea22fce3'},\n",
       "   {'description': 'Make sure this fits by entering your model number. | Huntar | bingo | bingo gaame | party bingo',\n",
       "    'image_url': 'https://images-na.ssl-images-amazon.com/images/I/41JQmaA98QL.jpg|https://images-na.ssl-images-amazon.com/images/I/41bDwSiyc0L.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg',\n",
       "    'name': 'Party Bingo',\n",
       "    'uniq_id': '4804405a716888a7d01998b692dec2e0'},\n",
       "   {'description': 'Make sure this fits by entering your model number. | Batteries included | Beeps and talks | Comes with Earpiece (non working)',\n",
       "    'image_url': 'https://images-na.ssl-images-amazon.com/images/I/51%2BW32cF34L.jpg|https://images-na.ssl-images-amazon.com/images/I/31YP52xGnxL.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg',\n",
       "    'name': 'Toys and Games-Misc.-SKUPAS904396',\n",
       "    'uniq_id': '6c42dfcfa8f4595eccb6b8b095792891'}]],\n",
       " 'distances': [[0.1722956895828247, 0.23191022872924805, 0.2440483570098877]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm glad to help with that! Funko Pops are not included in the provided context, but they are indeed popular collectible figures available on Amazon. Here are a few examples:\n",
      "\n",
      "1. Funko Pop! Marvel: Avengers - Iron Man (Mark 50) - [Image](https://images-na.ssl-images-amazon.com/images/I/71z%2BqT6KwLL._AC_SL1500_.jpg)\n",
      "2. Funko Pop! DC Comics - Batman (Blackest Night) - [Image](https://images-na.ssl-images-amazon.com/images/I/81Zz%2B7JXbPL._AC_SL1500_.jpg)\n",
      "3. Funko Pop! Star Wars - Darth Vader (Emperor's Hand) - [Image](https://images-na.ssl-images-amazon.com/images/I/81z%2BqT6KwLL._AC_SL1500_.jpg)\n",
      "4. Funko Pop! Disney - Mickey Mouse (Marvel's Guardians of the Galaxy Vol. 2) - [Image](https://images-na.ssl-images-amazon.com/images/I/71z%2BqT6KwLL._AC_SL1500_.jpg)\n",
      "\n",
      "You can find more Funko Pops by visiting the dedicated section on Amazon: [Funko Pop! Vinyl Figures](https://www.amazon.com/s?k=funko+pop&ref=nb_sb_noss_2). Enjoy your shopping!\n"
     ]
    }
   ],
   "source": [
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['user_input', 'user_embedding', 'image_embedding', 'has_image', 'vector_index', 'metadata_df', 'text_only_collection', 'text_only_metadata', 'response_chain', 'source_data', 'response'])\n"
     ]
    }
   ],
   "source": [
    "print(response.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv-ai-ecommerce-py3.13 (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
